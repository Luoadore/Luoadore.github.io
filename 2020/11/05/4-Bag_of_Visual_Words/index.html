






<!doctype html>
<html lang="zh_Hans">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  
  <meta name="author" content="Luoadore">
  
  
  
  
    <meta name="description" content="Bag of Visual WordsWhat is an bag of visual words?
Bag of visual words refers to techniques that allows us to compactly describe images and to perform similarities queries. So given a database of i...">
  
  <title>Bag of Visual Words [ Luoadore ]</title>
  
  
    <link rel="shortcut icon" href="/hollow.ico">
  
  
  
<link rel="stylesheet" href="/css/random.css">
<link rel="stylesheet" href="/css/vegas.min.css">
<link rel="stylesheet" href="/css/highlight-railscasts.css">
<link rel="stylesheet" href="/css/jquery.fancybox.css">
<link rel="stylesheet" href="/css/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/jquery.fancybox-thumbs.css">
<link rel="stylesheet" href="/css/plyr.css">

  
<meta name="generator" content="Hexo 5.2.0"></head>

<body>
<div class="side-navigate hide-area">
  
    <div class="item prev">
      <a href="/2020/11/06/3-Occupancy_Grid/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        Occupancy Grid
      </div>
    </div>
  
  
    <div class="item next">
      <a href="/2020/11/03/2-Particle_Filter/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        Particle Filter
      </div>
    </div>
  
</div>
<div id="outer-container" class="hide-area">
<div id="container">
  <div id="menu-outer" class="slide-down">
    <div id="menu-inner">
      <div id="brand">
        
        <a onClick="openUserCard()">
          <img id="avatar" src="https://avatars0.githubusercontent.com/u/27325158?s=460&u=943b90cabcb08165803593378c6afd6bca967ec5&v=4"/>
          <div id="homelink">Luoadore</div>
        </a>
      </div>
      <div id="menu-list">
        <ul>
        
        
          
            <li>
          
            <a href="/">Home</a>
            
          </li>
        
          
            <li>
          
            <a href="/archives">Archives</a>
            
          </li>
        
          
            <li>
          
            <a href="/tags">Tags</a>
            
          </li>
        
          
            <li>
          
            <a href="/interests">Hobbies</a>
            
          </li>
        
          
            <li>
          
            <a href="/about">About</a>
            
          </li>
        
        </ul>
      </div>
      <div id="show-menu">
        <button>Menu</button>
      </div>
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      
      
  

  <article id="post" style="padding: 10px;">
    <h1>Bag of Visual Words</h1>
    <p class="page-title-sub">
      <span id = "post-title-date">撰写于 2020-11-05</span>
      
        <span id = "post-title-updated">修改于 2021-04-29</span>
      
      
      
        <span id = "post-title-tags">
          标签
          
          
            
            
            <a href="/tags/5-Minutes-with-Cyrill/">5 Minutes with Cyrill</a>
          
        </span>
      
      <span id="/2020/11/05/4-Bag_of_Visual_Words/" class="leancloud-visitors" data-flag-title="Bag of Visual Words">
        <i class="leancloud-visitors-count"></i>
        <em class="post-meta-item-text"> views </em>
      </span>
    </p>
    
    <h1 id="Bag-of-Visual-Words"><a href="#Bag-of-Visual-Words" class="headerlink" title="Bag of Visual Words"></a>Bag of Visual Words</h1><p>What is an bag of visual words?</p>
<p>Bag of visual words refers to techniques that allows us to compactly describe images and to perform similarities queries. So given a database of images the bag of visual words approach can be used to efficiently find subsets of images that look similar either among each other or with respect to a given query image. So how does that work? So the bag of visual words uses a set of <strong>image features as so-called visual words</strong>. Then it describes the images by simply counting how often individual visual words appear in an image. So here’s an example of a regular image what we can do we can extract part locations at which e compute feature descriptors such as sift features and are shown over here. So let us illustrate the different visual words now with colored boxes, each color box means there’s an occurrence of one visual word. Of course this is a very simplified illustration here  just showing a few visual words. </p>
<p><img src="/2020/11/05/4-Bag_of_Visual_Words/sift-features.png" alt="sift-features">      <img src="/2020/11/05/4-Bag_of_Visual_Words/illustration-visual-words.png" alt="illustration-visual-words"></p>
<p>So in the end each image is reduced to visual words and the actual pixel values do not matter anymore.  So in bag of words, each image becomes in histogram simply counting the occurrences of the visual words within this image. So the x axis of the histogram defines the visual words while the y axis of the histogram how often the individual visual words appear in the image. </p>
<p>A visual word can be a single feature, most approaches however will use the mean feature descriptor computed from several similar descriptors at the visual _. That means we are grouping visual features together into one word in this grouping is typically computed using a clustering algorithm such as k-means. The visual words that result from clustering are called the dictionary. And they are lists of visual words and they define the x axis of all our histograms. So each image in our database is turned into such histogram so that need to store M histograms instead of M images in our database. And all <strong>comparisons are reduced</strong> to computing the similarity between histograms. And we are not considering the actual images anymore.</p>
<p>And there is however an issue with this approach because in practice some visual words are good for performing such a comparisons while others are less expressive. So for example if you have a word which occurs in every image will not be a great support for making comparisons. So we can fix this issue by computing a weight for each visual word depending on the expected information it is going to convey. So important visual words are ranked higher and others are lower. This is done using the so-called <strong>TF-IDT</strong>, tf-idf stands for <strong>term frequency inverse document frequency</strong>. </p>
<p><img src="/2020/11/05/4-Bag_of_Visual_Words/tf-idf.png" alt="tf-idf"></p>
<p>The first term in this equation is the relative occurrence of a word in image such as our histogram just normalized to 1, this term then multiplied with the logarithm of the inverse percentage of images in our database contain the word at all. This will bring the importance of the words that appear in every image down to 0. Other more rarely occurring words are enhanced. So tf-idf will relate each bin of each histogram individually and that expressive visual word will be enhanced. This tf-idf computations on all histogram in our database and now we are ready for comparing images in the database either among each other of respect to a query image. </p>
<p>So let’s consider more example with 4 images shown over here. </p>
<p><img src="/2020/11/05/4-Bag_of_Visual_Words/examples.png" alt="examples"></p>
<p>And this example number 0 and number 3 are similar to each other. By looking into the cost matrix of the histograms, we can see that each histogram compared with itself has a distance of 0 and all other comparisons lead to higher values actually not all of them. We also see the image number 0 and number 3 have a distance of zero which means they have the same distribution of related features and such they are considered to be similar or maybe identical. </p>
<p><img src="/2020/11/05/4-Bag_of_Visual_Words/cost-matrix.png" alt="cost-matrix"></p>
<p>In the bag of words model we typically compare these histograms using the cosine distance which takes value between 0 and 1. So in order to find the N most similar images in database given _ images we will <strong>return the N images which have the smallest cosine distance</strong>.  So that’s basically of it, that’s how we defined similar images. So the bag of words approach frequently used in computer vision for finding similar images. Also in robotics it’s used for performing place recognition tasks or for finding loop closure candidates in the context of the slam program. If you wanna to investigate the bag of visual words approach further, I suggest you to visit the <a target="_blank" rel="noopener" href="https://github.com/ovysotska/in_simple_english">jupiter notebook</a> that was created by ovysotska and which is available on github. It’s a great point for understanding the effect of tf-idf and also the distance functions. </p>

  </article>
  <div class="random-toc-area">
  <button class="btn-hide-toc btn-hide-toc-show" style="display: none" onclick="TOCToggle()">显示目录</button>
  <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">隐藏目录</button>
  <div class="random-toc">
    <h2>目录</h2>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Bag-of-Visual-Words"><span class="toc-text">Bag of Visual Words</span></a></li></ol>
  </div>
</div>

  
  
<nav id="pagination">
  
    <a href="/2020/11/06/3-Occupancy_Grid/" class="prev">&larr; 上一篇 Occupancy Grid</a>
  

  

  
    <a href="/2020/11/03/2-Particle_Filter/" class="next">下一篇 Particle Filter &rarr;</a>
  
</nav>

  <!-- JiaThis Button BEGIN -->

<!-- JiaThis Button END -->


      
      
    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      Site by Luoadore using
      <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/stiekel/hexo-theme-random">Random</a>
      <br>
      
    </div>
  </div>
</div>

</div>


<div id="user-card">
  <div class="center-field">
    <img class="avatar" src="https://avatars0.githubusercontent.com/u/27325158?s=460&u=943b90cabcb08165803593378c6afd6bca967ec5&v=4">
    <p id="description"></p>
    <ul class="social-icon">
  
  
    <li>
      
        
      
      <a target="_blank" rel="noopener" href="https://github.com/Luoadore/">
        
          <i class="icon iconfont icongithub" title="github"></i> 
        
      </a>
    </li>
  
    <li>
      
        
      
      <a href="mailto:luoluomayday@gmail.com">
        
          <i class="icon iconfont iconyoujian" title="luoluomayday@gmail.com"></i> 
        
      </a>
    </li>
  
    <li>
      
        
      
      <a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=yuDQY0YAAAAJ&hl=zh-CN">
        
          <i class="icon iconfont icongoogle" title="GoogleSchilar"></i>
        
      </a>
    </li>
  
    <li>
      
        
      
      <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/%E9%9B%85%E6%A5%A0-%E9%9B%92-84482b91/">
        
          <i class="icon iconfont iconlinkedin" title="LinkedIn"></i>
        
      </a>
    </li>
  
</ul>
  </div>
</div>


<script>
// is trigger analytics / tongji script
var isIgnoreHost = false;

if(window && window.location && window.location.host) {
  isIgnoreHost = ["localhost","127.0.0.1"].some(function(address){
    return 0 === window.location.host.indexOf(address);
  });
}

var isTriggerAnalytics = !( true && isIgnoreHost );

</script>




  
  
    <script src="/js/jquery-2.2.3.min.js"></script>
  
    <script src="/js/vegas.min.js"></script>
  
    <script src="/js/random.js"></script>
  
    <script src="/js/highlight.pack.js"></script>
  
    <script src="/js/jquery.mousewheel.pack.js"></script>
  
    <script src="/js/jquery.fancybox.pack.js"></script>
  
    <script src="/js/jquery.fancybox-thumbs.js"></script>
  
    <script src="/js/plyr.js"></script>
  

<script>

  // fancybox
  var backgroundImages = [];
  
    
      backgroundImages.push('http://cdn.chenqihulk.cn/luo.jpeg');
    
  
  $('#post').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox') || $(this).parent().hasClass('fancybox-thumb')) return;
      var alt = this.alt || this.title;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'post' + i);
    });
  });
  $(".fancybox").fancybox();

var vegasConfig = {"preload­Image":true,"transition":null,"timer":false,"delay":1500000,"shuffle":false,"count":12};
var unsplashConfig = {"gravity":"center"};
// is show background images
var turnoffBackgroundImage = false;




var backgroundColor = 576094;

$(".fancybox-thumb").fancybox({
  prevEffect: 'none',
  nextEffect: 'none',
  helpers: {
    title: {
      type: 'outside'
    },
    thumbs: {
      width: 50,
      height: 50
    }
  }
});

// show video with plyr
$(".video-container iframe").each(function(i){
  var url = $(this).attr('src');
  var id = url.split('/').pop();
  var plyrContainer = document.createElement('div');
  plyrContainer.className = 'plyr';
  var plyrElement = document.createElement('div');
  plyrElement.dataset.videoId = id;
  switch(true) {
    case url.search('youtube.com') >= 0:
      plyrElement.dataset.type = 'youtube';
      break;
    case url.search('vimeo.com') >= 0:
      plyrElement.dataset.type = 'vimeo';
      break;
    default:
      return;
  };
  plyrContainer.appendChild(plyrElement);
  $(this).parent().html(plyrContainer);
});
plyr.setup('.plyr', {iconUrl: '/css/sprite.svg'});
</script>
</body>
</html>

